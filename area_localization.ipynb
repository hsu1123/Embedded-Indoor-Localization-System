{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_fscore_support\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>RSSI_1</th>\n",
       "      <th>proximity_1</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>RSSI_2</th>\n",
       "      <th>proximity_2</th>\n",
       "      <th>accuracy_2</th>\n",
       "      <th>RSSI_3</th>\n",
       "      <th>proximity_3</th>\n",
       "      <th>accuracy_3</th>\n",
       "      <th>RSSI_4</th>\n",
       "      <th>proximity_4</th>\n",
       "      <th>accuracy_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>-70</td>\n",
       "      <td>far</td>\n",
       "      <td>13.851972</td>\n",
       "      <td>-58</td>\n",
       "      <td>far</td>\n",
       "      <td>6.287733</td>\n",
       "      <td>-61</td>\n",
       "      <td>far</td>\n",
       "      <td>8.067809</td>\n",
       "      <td>-65</td>\n",
       "      <td>far</td>\n",
       "      <td>7.121443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>-71</td>\n",
       "      <td>far</td>\n",
       "      <td>14.259079</td>\n",
       "      <td>-60</td>\n",
       "      <td>far</td>\n",
       "      <td>5.878623</td>\n",
       "      <td>-61</td>\n",
       "      <td>far</td>\n",
       "      <td>7.542129</td>\n",
       "      <td>-63</td>\n",
       "      <td>far</td>\n",
       "      <td>7.071776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>far</td>\n",
       "      <td>14.302249</td>\n",
       "      <td>-60</td>\n",
       "      <td>far</td>\n",
       "      <td>5.603389</td>\n",
       "      <td>-63</td>\n",
       "      <td>far</td>\n",
       "      <td>7.435441</td>\n",
       "      <td>-60</td>\n",
       "      <td>far</td>\n",
       "      <td>6.549222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>far</td>\n",
       "      <td>14.341001</td>\n",
       "      <td>-62</td>\n",
       "      <td>far</td>\n",
       "      <td>5.669041</td>\n",
       "      <td>-65</td>\n",
       "      <td>far</td>\n",
       "      <td>7.595746</td>\n",
       "      <td>-62</td>\n",
       "      <td>far</td>\n",
       "      <td>6.458476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>far</td>\n",
       "      <td>14.375774</td>\n",
       "      <td>-72</td>\n",
       "      <td>far</td>\n",
       "      <td>6.493668</td>\n",
       "      <td>-62</td>\n",
       "      <td>far</td>\n",
       "      <td>7.327017</td>\n",
       "      <td>-63</td>\n",
       "      <td>far</td>\n",
       "      <td>6.509904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>C</td>\n",
       "      <td>-66</td>\n",
       "      <td>far</td>\n",
       "      <td>7.082790</td>\n",
       "      <td>-71</td>\n",
       "      <td>far</td>\n",
       "      <td>18.131115</td>\n",
       "      <td>-68</td>\n",
       "      <td>far</td>\n",
       "      <td>17.088874</td>\n",
       "      <td>-73</td>\n",
       "      <td>far</td>\n",
       "      <td>22.150106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>C</td>\n",
       "      <td>-66</td>\n",
       "      <td>far</td>\n",
       "      <td>8.452925</td>\n",
       "      <td>-69</td>\n",
       "      <td>far</td>\n",
       "      <td>18.347707</td>\n",
       "      <td>-79</td>\n",
       "      <td>far</td>\n",
       "      <td>19.353247</td>\n",
       "      <td>-78</td>\n",
       "      <td>far</td>\n",
       "      <td>24.354757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>C</td>\n",
       "      <td>-64</td>\n",
       "      <td>far</td>\n",
       "      <td>8.342343</td>\n",
       "      <td>-72</td>\n",
       "      <td>far</td>\n",
       "      <td>18.672650</td>\n",
       "      <td>-80</td>\n",
       "      <td>far</td>\n",
       "      <td>20.681886</td>\n",
       "      <td>-77</td>\n",
       "      <td>far</td>\n",
       "      <td>25.227219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>C</td>\n",
       "      <td>-67</td>\n",
       "      <td>far</td>\n",
       "      <td>8.669814</td>\n",
       "      <td>-68</td>\n",
       "      <td>far</td>\n",
       "      <td>17.781409</td>\n",
       "      <td>-78</td>\n",
       "      <td>far</td>\n",
       "      <td>21.814865</td>\n",
       "      <td>-74</td>\n",
       "      <td>far</td>\n",
       "      <td>25.428526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>C</td>\n",
       "      <td>-69</td>\n",
       "      <td>far</td>\n",
       "      <td>9.195146</td>\n",
       "      <td>-67</td>\n",
       "      <td>far</td>\n",
       "      <td>16.750874</td>\n",
       "      <td>-77</td>\n",
       "      <td>far</td>\n",
       "      <td>22.795167</td>\n",
       "      <td>-74</td>\n",
       "      <td>far</td>\n",
       "      <td>25.613792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label  RSSI_1 proximity_1  accuracy_1  RSSI_2 proximity_2  accuracy_2  \\\n",
       "0       A     -70         far   13.851972     -58         far    6.287733   \n",
       "1       A     -71         far   14.259079     -60         far    5.878623   \n",
       "2       A     -69         far   14.302249     -60         far    5.603389   \n",
       "3       A     -69         far   14.341001     -62         far    5.669041   \n",
       "4       A     -69         far   14.375774     -72         far    6.493668   \n",
       "..    ...     ...         ...         ...     ...         ...         ...   \n",
       "253     C     -66         far    7.082790     -71         far   18.131115   \n",
       "254     C     -66         far    8.452925     -69         far   18.347707   \n",
       "255     C     -64         far    8.342343     -72         far   18.672650   \n",
       "256     C     -67         far    8.669814     -68         far   17.781409   \n",
       "257     C     -69         far    9.195146     -67         far   16.750874   \n",
       "\n",
       "     RSSI_3 proximity_3  accuracy_3  RSSI_4 proximity_4  accuracy_4  \n",
       "0       -61         far    8.067809     -65         far    7.121443  \n",
       "1       -61         far    7.542129     -63         far    7.071776  \n",
       "2       -63         far    7.435441     -60         far    6.549222  \n",
       "3       -65         far    7.595746     -62         far    6.458476  \n",
       "4       -62         far    7.327017     -63         far    6.509904  \n",
       "..      ...         ...         ...     ...         ...         ...  \n",
       "253     -68         far   17.088874     -73         far   22.150106  \n",
       "254     -79         far   19.353247     -78         far   24.354757  \n",
       "255     -80         far   20.681886     -77         far   25.227219  \n",
       "256     -78         far   21.814865     -74         far   25.428526  \n",
       "257     -77         far   22.795167     -74         far   25.613792  \n",
       "\n",
       "[258 rows x 13 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_area_2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = df.Label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 83, 86)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(dt==\"A\")[0]), len(np.where(dt==\"B\")[0]), len(np.where(dt==\"C\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>RSSI_1</th>\n",
       "      <th>proximity_1</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>RSSI_2</th>\n",
       "      <th>proximity_2</th>\n",
       "      <th>accuracy_2</th>\n",
       "      <th>RSSI_3</th>\n",
       "      <th>proximity_3</th>\n",
       "      <th>accuracy_3</th>\n",
       "      <th>...</th>\n",
       "      <th>proximity_1_far</th>\n",
       "      <th>proximity_1_near</th>\n",
       "      <th>proximity_1_unknow</th>\n",
       "      <th>proximity_2_far</th>\n",
       "      <th>proximity_2_near</th>\n",
       "      <th>proximity_3_far</th>\n",
       "      <th>proximity_3_near</th>\n",
       "      <th>proximity_4_far</th>\n",
       "      <th>proximity_4_near</th>\n",
       "      <th>proximity_4_unknow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>-70</td>\n",
       "      <td>far</td>\n",
       "      <td>13.851972</td>\n",
       "      <td>-58</td>\n",
       "      <td>far</td>\n",
       "      <td>6.287733</td>\n",
       "      <td>-61</td>\n",
       "      <td>far</td>\n",
       "      <td>8.067809</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>-71</td>\n",
       "      <td>far</td>\n",
       "      <td>14.259079</td>\n",
       "      <td>-60</td>\n",
       "      <td>far</td>\n",
       "      <td>5.878623</td>\n",
       "      <td>-61</td>\n",
       "      <td>far</td>\n",
       "      <td>7.542129</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>far</td>\n",
       "      <td>14.302249</td>\n",
       "      <td>-60</td>\n",
       "      <td>far</td>\n",
       "      <td>5.603389</td>\n",
       "      <td>-63</td>\n",
       "      <td>far</td>\n",
       "      <td>7.435441</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>far</td>\n",
       "      <td>14.341001</td>\n",
       "      <td>-62</td>\n",
       "      <td>far</td>\n",
       "      <td>5.669041</td>\n",
       "      <td>-65</td>\n",
       "      <td>far</td>\n",
       "      <td>7.595746</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>far</td>\n",
       "      <td>14.375774</td>\n",
       "      <td>-72</td>\n",
       "      <td>far</td>\n",
       "      <td>6.493668</td>\n",
       "      <td>-62</td>\n",
       "      <td>far</td>\n",
       "      <td>7.327017</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>C</td>\n",
       "      <td>-66</td>\n",
       "      <td>far</td>\n",
       "      <td>7.082790</td>\n",
       "      <td>-71</td>\n",
       "      <td>far</td>\n",
       "      <td>18.131115</td>\n",
       "      <td>-68</td>\n",
       "      <td>far</td>\n",
       "      <td>17.088874</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>C</td>\n",
       "      <td>-66</td>\n",
       "      <td>far</td>\n",
       "      <td>8.452925</td>\n",
       "      <td>-69</td>\n",
       "      <td>far</td>\n",
       "      <td>18.347707</td>\n",
       "      <td>-79</td>\n",
       "      <td>far</td>\n",
       "      <td>19.353247</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>C</td>\n",
       "      <td>-64</td>\n",
       "      <td>far</td>\n",
       "      <td>8.342343</td>\n",
       "      <td>-72</td>\n",
       "      <td>far</td>\n",
       "      <td>18.672650</td>\n",
       "      <td>-80</td>\n",
       "      <td>far</td>\n",
       "      <td>20.681886</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>C</td>\n",
       "      <td>-67</td>\n",
       "      <td>far</td>\n",
       "      <td>8.669814</td>\n",
       "      <td>-68</td>\n",
       "      <td>far</td>\n",
       "      <td>17.781409</td>\n",
       "      <td>-78</td>\n",
       "      <td>far</td>\n",
       "      <td>21.814865</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>C</td>\n",
       "      <td>-69</td>\n",
       "      <td>far</td>\n",
       "      <td>9.195146</td>\n",
       "      <td>-67</td>\n",
       "      <td>far</td>\n",
       "      <td>16.750874</td>\n",
       "      <td>-77</td>\n",
       "      <td>far</td>\n",
       "      <td>22.795167</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label  RSSI_1 proximity_1  accuracy_1  RSSI_2 proximity_2  accuracy_2  \\\n",
       "0       A     -70         far   13.851972     -58         far    6.287733   \n",
       "1       A     -71         far   14.259079     -60         far    5.878623   \n",
       "2       A     -69         far   14.302249     -60         far    5.603389   \n",
       "3       A     -69         far   14.341001     -62         far    5.669041   \n",
       "4       A     -69         far   14.375774     -72         far    6.493668   \n",
       "..    ...     ...         ...         ...     ...         ...         ...   \n",
       "253     C     -66         far    7.082790     -71         far   18.131115   \n",
       "254     C     -66         far    8.452925     -69         far   18.347707   \n",
       "255     C     -64         far    8.342343     -72         far   18.672650   \n",
       "256     C     -67         far    8.669814     -68         far   17.781409   \n",
       "257     C     -69         far    9.195146     -67         far   16.750874   \n",
       "\n",
       "     RSSI_3 proximity_3  accuracy_3  ...  proximity_1_far proximity_1_near  \\\n",
       "0       -61         far    8.067809  ...                1                0   \n",
       "1       -61         far    7.542129  ...                1                0   \n",
       "2       -63         far    7.435441  ...                1                0   \n",
       "3       -65         far    7.595746  ...                1                0   \n",
       "4       -62         far    7.327017  ...                1                0   \n",
       "..      ...         ...         ...  ...              ...              ...   \n",
       "253     -68         far   17.088874  ...                1                0   \n",
       "254     -79         far   19.353247  ...                1                0   \n",
       "255     -80         far   20.681886  ...                1                0   \n",
       "256     -78         far   21.814865  ...                1                0   \n",
       "257     -77         far   22.795167  ...                1                0   \n",
       "\n",
       "     proximity_1_unknow  proximity_2_far  proximity_2_near  proximity_3_far  \\\n",
       "0                     0                1                 0                1   \n",
       "1                     0                1                 0                1   \n",
       "2                     0                1                 0                1   \n",
       "3                     0                1                 0                1   \n",
       "4                     0                1                 0                1   \n",
       "..                  ...              ...               ...              ...   \n",
       "253                   0                1                 0                1   \n",
       "254                   0                1                 0                1   \n",
       "255                   0                1                 0                1   \n",
       "256                   0                1                 0                1   \n",
       "257                   0                1                 0                1   \n",
       "\n",
       "     proximity_3_near  proximity_4_far  proximity_4_near  proximity_4_unknow  \n",
       "0                   0                1                 0                   0  \n",
       "1                   0                1                 0                   0  \n",
       "2                   0                1                 0                   0  \n",
       "3                   0                1                 0                   0  \n",
       "4                   0                1                 0                   0  \n",
       "..                ...              ...               ...                 ...  \n",
       "253                 0                1                 0                   0  \n",
       "254                 0                1                 0                   0  \n",
       "255                 0                1                 0                   0  \n",
       "256                 0                1                 0                   0  \n",
       "257                 0                1                 0                   0  \n",
       "\n",
       "[258 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proximity_1_dummies = pd.get_dummies(df.proximity_1,prefix='proximity_1',dtype=int)\n",
    "proximity_2_dummies = pd.get_dummies(df.proximity_2,prefix='proximity_2',dtype=int)\n",
    "proximity_3_dummies = pd.get_dummies(df.proximity_3,prefix='proximity_3',dtype=int)\n",
    "proximity_4_dummies = pd.get_dummies(df.proximity_4,prefix='proximity_4',dtype=int)\n",
    "df = pd.concat([df, proximity_1_dummies,proximity_2_dummies, proximity_3_dummies, proximity_4_dummies], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df['proximity_2_far'] = 1\\ndf['proximity_2_near'] = 0\\ndf\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#becauce proximity does not conatin near\n",
    "'''df['proximity_2_far'] = 1\n",
    "df['proximity_2_near'] = 0\n",
    "df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>RSSI_1</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>RSSI_2</th>\n",
       "      <th>accuracy_2</th>\n",
       "      <th>RSSI_3</th>\n",
       "      <th>accuracy_3</th>\n",
       "      <th>RSSI_4</th>\n",
       "      <th>accuracy_4</th>\n",
       "      <th>proximity_1_far</th>\n",
       "      <th>proximity_1_near</th>\n",
       "      <th>proximity_1_unknow</th>\n",
       "      <th>proximity_2_far</th>\n",
       "      <th>proximity_2_near</th>\n",
       "      <th>proximity_3_far</th>\n",
       "      <th>proximity_3_near</th>\n",
       "      <th>proximity_4_far</th>\n",
       "      <th>proximity_4_near</th>\n",
       "      <th>proximity_4_unknow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>-70</td>\n",
       "      <td>13.851972</td>\n",
       "      <td>-58</td>\n",
       "      <td>6.287733</td>\n",
       "      <td>-61</td>\n",
       "      <td>8.067809</td>\n",
       "      <td>-65</td>\n",
       "      <td>7.121443</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>-71</td>\n",
       "      <td>14.259079</td>\n",
       "      <td>-60</td>\n",
       "      <td>5.878623</td>\n",
       "      <td>-61</td>\n",
       "      <td>7.542129</td>\n",
       "      <td>-63</td>\n",
       "      <td>7.071776</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>14.302249</td>\n",
       "      <td>-60</td>\n",
       "      <td>5.603389</td>\n",
       "      <td>-63</td>\n",
       "      <td>7.435441</td>\n",
       "      <td>-60</td>\n",
       "      <td>6.549222</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>14.341001</td>\n",
       "      <td>-62</td>\n",
       "      <td>5.669041</td>\n",
       "      <td>-65</td>\n",
       "      <td>7.595746</td>\n",
       "      <td>-62</td>\n",
       "      <td>6.458476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>14.375774</td>\n",
       "      <td>-72</td>\n",
       "      <td>6.493668</td>\n",
       "      <td>-62</td>\n",
       "      <td>7.327017</td>\n",
       "      <td>-63</td>\n",
       "      <td>6.509904</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>C</td>\n",
       "      <td>-66</td>\n",
       "      <td>7.082790</td>\n",
       "      <td>-71</td>\n",
       "      <td>18.131115</td>\n",
       "      <td>-68</td>\n",
       "      <td>17.088874</td>\n",
       "      <td>-73</td>\n",
       "      <td>22.150106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>C</td>\n",
       "      <td>-66</td>\n",
       "      <td>8.452925</td>\n",
       "      <td>-69</td>\n",
       "      <td>18.347707</td>\n",
       "      <td>-79</td>\n",
       "      <td>19.353247</td>\n",
       "      <td>-78</td>\n",
       "      <td>24.354757</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>C</td>\n",
       "      <td>-64</td>\n",
       "      <td>8.342343</td>\n",
       "      <td>-72</td>\n",
       "      <td>18.672650</td>\n",
       "      <td>-80</td>\n",
       "      <td>20.681886</td>\n",
       "      <td>-77</td>\n",
       "      <td>25.227219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>C</td>\n",
       "      <td>-67</td>\n",
       "      <td>8.669814</td>\n",
       "      <td>-68</td>\n",
       "      <td>17.781409</td>\n",
       "      <td>-78</td>\n",
       "      <td>21.814865</td>\n",
       "      <td>-74</td>\n",
       "      <td>25.428526</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>C</td>\n",
       "      <td>-69</td>\n",
       "      <td>9.195146</td>\n",
       "      <td>-67</td>\n",
       "      <td>16.750874</td>\n",
       "      <td>-77</td>\n",
       "      <td>22.795167</td>\n",
       "      <td>-74</td>\n",
       "      <td>25.613792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label  RSSI_1  accuracy_1  RSSI_2  accuracy_2  RSSI_3  accuracy_3  RSSI_4  \\\n",
       "0       A     -70   13.851972     -58    6.287733     -61    8.067809     -65   \n",
       "1       A     -71   14.259079     -60    5.878623     -61    7.542129     -63   \n",
       "2       A     -69   14.302249     -60    5.603389     -63    7.435441     -60   \n",
       "3       A     -69   14.341001     -62    5.669041     -65    7.595746     -62   \n",
       "4       A     -69   14.375774     -72    6.493668     -62    7.327017     -63   \n",
       "..    ...     ...         ...     ...         ...     ...         ...     ...   \n",
       "253     C     -66    7.082790     -71   18.131115     -68   17.088874     -73   \n",
       "254     C     -66    8.452925     -69   18.347707     -79   19.353247     -78   \n",
       "255     C     -64    8.342343     -72   18.672650     -80   20.681886     -77   \n",
       "256     C     -67    8.669814     -68   17.781409     -78   21.814865     -74   \n",
       "257     C     -69    9.195146     -67   16.750874     -77   22.795167     -74   \n",
       "\n",
       "     accuracy_4  proximity_1_far  proximity_1_near  proximity_1_unknow  \\\n",
       "0      7.121443                1                 0                   0   \n",
       "1      7.071776                1                 0                   0   \n",
       "2      6.549222                1                 0                   0   \n",
       "3      6.458476                1                 0                   0   \n",
       "4      6.509904                1                 0                   0   \n",
       "..          ...              ...               ...                 ...   \n",
       "253   22.150106                1                 0                   0   \n",
       "254   24.354757                1                 0                   0   \n",
       "255   25.227219                1                 0                   0   \n",
       "256   25.428526                1                 0                   0   \n",
       "257   25.613792                1                 0                   0   \n",
       "\n",
       "     proximity_2_far  proximity_2_near  proximity_3_far  proximity_3_near  \\\n",
       "0                  1                 0                1                 0   \n",
       "1                  1                 0                1                 0   \n",
       "2                  1                 0                1                 0   \n",
       "3                  1                 0                1                 0   \n",
       "4                  1                 0                1                 0   \n",
       "..               ...               ...              ...               ...   \n",
       "253                1                 0                1                 0   \n",
       "254                1                 0                1                 0   \n",
       "255                1                 0                1                 0   \n",
       "256                1                 0                1                 0   \n",
       "257                1                 0                1                 0   \n",
       "\n",
       "     proximity_4_far  proximity_4_near  proximity_4_unknow  \n",
       "0                  1                 0                   0  \n",
       "1                  1                 0                   0  \n",
       "2                  1                 0                   0  \n",
       "3                  1                 0                   0  \n",
       "4                  1                 0                   0  \n",
       "..               ...               ...                 ...  \n",
       "253                1                 0                   0  \n",
       "254                1                 0                   0  \n",
       "255                1                 0                   0  \n",
       "256                1                 0                   0  \n",
       "257                1                 0                   0  \n",
       "\n",
       "[258 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['proximity_1', 'proximity_2', 'proximity_3', 'proximity_4'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>RSSI_1</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>RSSI_2</th>\n",
       "      <th>accuracy_2</th>\n",
       "      <th>RSSI_3</th>\n",
       "      <th>accuracy_3</th>\n",
       "      <th>RSSI_4</th>\n",
       "      <th>accuracy_4</th>\n",
       "      <th>proximity_1_far</th>\n",
       "      <th>proximity_1_near</th>\n",
       "      <th>proximity_2_far</th>\n",
       "      <th>proximity_2_near</th>\n",
       "      <th>proximity_3_far</th>\n",
       "      <th>proximity_3_near</th>\n",
       "      <th>proximity_4_far</th>\n",
       "      <th>proximity_4_near</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>-70</td>\n",
       "      <td>13.851972</td>\n",
       "      <td>-58</td>\n",
       "      <td>6.287733</td>\n",
       "      <td>-61</td>\n",
       "      <td>8.067809</td>\n",
       "      <td>-65</td>\n",
       "      <td>7.121443</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>-71</td>\n",
       "      <td>14.259079</td>\n",
       "      <td>-60</td>\n",
       "      <td>5.878623</td>\n",
       "      <td>-61</td>\n",
       "      <td>7.542129</td>\n",
       "      <td>-63</td>\n",
       "      <td>7.071776</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>14.302249</td>\n",
       "      <td>-60</td>\n",
       "      <td>5.603389</td>\n",
       "      <td>-63</td>\n",
       "      <td>7.435441</td>\n",
       "      <td>-60</td>\n",
       "      <td>6.549222</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>14.341001</td>\n",
       "      <td>-62</td>\n",
       "      <td>5.669041</td>\n",
       "      <td>-65</td>\n",
       "      <td>7.595746</td>\n",
       "      <td>-62</td>\n",
       "      <td>6.458476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>-69</td>\n",
       "      <td>14.375774</td>\n",
       "      <td>-72</td>\n",
       "      <td>6.493668</td>\n",
       "      <td>-62</td>\n",
       "      <td>7.327017</td>\n",
       "      <td>-63</td>\n",
       "      <td>6.509904</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>C</td>\n",
       "      <td>-66</td>\n",
       "      <td>7.082790</td>\n",
       "      <td>-71</td>\n",
       "      <td>18.131115</td>\n",
       "      <td>-68</td>\n",
       "      <td>17.088874</td>\n",
       "      <td>-73</td>\n",
       "      <td>22.150106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>C</td>\n",
       "      <td>-66</td>\n",
       "      <td>8.452925</td>\n",
       "      <td>-69</td>\n",
       "      <td>18.347707</td>\n",
       "      <td>-79</td>\n",
       "      <td>19.353247</td>\n",
       "      <td>-78</td>\n",
       "      <td>24.354757</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>C</td>\n",
       "      <td>-64</td>\n",
       "      <td>8.342343</td>\n",
       "      <td>-72</td>\n",
       "      <td>18.672650</td>\n",
       "      <td>-80</td>\n",
       "      <td>20.681886</td>\n",
       "      <td>-77</td>\n",
       "      <td>25.227219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>C</td>\n",
       "      <td>-67</td>\n",
       "      <td>8.669814</td>\n",
       "      <td>-68</td>\n",
       "      <td>17.781409</td>\n",
       "      <td>-78</td>\n",
       "      <td>21.814865</td>\n",
       "      <td>-74</td>\n",
       "      <td>25.428526</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>C</td>\n",
       "      <td>-69</td>\n",
       "      <td>9.195146</td>\n",
       "      <td>-67</td>\n",
       "      <td>16.750874</td>\n",
       "      <td>-77</td>\n",
       "      <td>22.795167</td>\n",
       "      <td>-74</td>\n",
       "      <td>25.613792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label  RSSI_1  accuracy_1  RSSI_2  accuracy_2  RSSI_3  accuracy_3  RSSI_4  \\\n",
       "0       A     -70   13.851972     -58    6.287733     -61    8.067809     -65   \n",
       "1       A     -71   14.259079     -60    5.878623     -61    7.542129     -63   \n",
       "2       A     -69   14.302249     -60    5.603389     -63    7.435441     -60   \n",
       "3       A     -69   14.341001     -62    5.669041     -65    7.595746     -62   \n",
       "4       A     -69   14.375774     -72    6.493668     -62    7.327017     -63   \n",
       "..    ...     ...         ...     ...         ...     ...         ...     ...   \n",
       "253     C     -66    7.082790     -71   18.131115     -68   17.088874     -73   \n",
       "254     C     -66    8.452925     -69   18.347707     -79   19.353247     -78   \n",
       "255     C     -64    8.342343     -72   18.672650     -80   20.681886     -77   \n",
       "256     C     -67    8.669814     -68   17.781409     -78   21.814865     -74   \n",
       "257     C     -69    9.195146     -67   16.750874     -77   22.795167     -74   \n",
       "\n",
       "     accuracy_4  proximity_1_far  proximity_1_near  proximity_2_far  \\\n",
       "0      7.121443                1                 0                1   \n",
       "1      7.071776                1                 0                1   \n",
       "2      6.549222                1                 0                1   \n",
       "3      6.458476                1                 0                1   \n",
       "4      6.509904                1                 0                1   \n",
       "..          ...              ...               ...              ...   \n",
       "253   22.150106                1                 0                1   \n",
       "254   24.354757                1                 0                1   \n",
       "255   25.227219                1                 0                1   \n",
       "256   25.428526                1                 0                1   \n",
       "257   25.613792                1                 0                1   \n",
       "\n",
       "     proximity_2_near  proximity_3_far  proximity_3_near  proximity_4_far  \\\n",
       "0                   0                1                 0                1   \n",
       "1                   0                1                 0                1   \n",
       "2                   0                1                 0                1   \n",
       "3                   0                1                 0                1   \n",
       "4                   0                1                 0                1   \n",
       "..                ...              ...               ...              ...   \n",
       "253                 0                1                 0                1   \n",
       "254                 0                1                 0                1   \n",
       "255                 0                1                 0                1   \n",
       "256                 0                1                 0                1   \n",
       "257                 0                1                 0                1   \n",
       "\n",
       "     proximity_4_near  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "..                ...  \n",
       "253                 0  \n",
       "254                 0  \n",
       "255                 0  \n",
       "256                 0  \n",
       "257                 0  \n",
       "\n",
       "[258 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['proximity_1_unknow', 'proximity_4_unknow'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = []\n",
    "for area in df.Label.values:\n",
    "    if area == 'A':\n",
    "        label.append(0)\n",
    "    elif area == 'B':\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(2)\n",
    "label = np.asarray(label)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RSSI_1', 'accuracy_1', 'RSSI_2', 'accuracy_2', 'RSSI_3', 'accuracy_3',\n",
       "       'RSSI_4', 'accuracy_4', 'proximity_1_far', 'proximity_1_near',\n",
       "       'proximity_2_far', 'proximity_2_near', 'proximity_3_far',\n",
       "       'proximity_3_near', 'proximity_4_far', 'proximity_4_near'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.loc[:,df.columns[1:]]\n",
    "#features = essentia_df.loc[:,top_features]\n",
    "features = np.asarray(features)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((206, 16), (52, 16), (206,), (52,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, label, test_size=0.2, random_state=42)\n",
    "train_features.shape, test_features.shape,  train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, label):\n",
    "      self.features = features\n",
    "      self.labels = label\n",
    "    def __getitem__(self, index):\n",
    "      features = self.features[index]    \n",
    "      label = self.labels[index]\n",
    "      return features, label\n",
    "    def __len__(self):\n",
    "      return len(self.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(train_features)\n",
    "train_feature = scaler.transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.52087379e+01  1.17634529e+01 -6.38786408e+01  8.40177676e+00\n",
      " -6.43106796e+01  8.96885582e+00 -6.75485437e+01  1.38230567e+01\n",
      "  9.22330097e-01  6.31067961e-02  9.66019417e-01  3.39805825e-02\n",
      "  9.41747573e-01  5.82524272e-02  9.75728155e-01  1.94174757e-02]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(16,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "        self.linear2 = nn.Linear(8,3)\n",
    "    def forward(self, features):   \n",
    "        '''for i in range(len(scaler.var_)):\n",
    "            features[:,i] = (features[:,i] - scaler.mean_[i]) / scaler.var_[i]'''\n",
    "        #outputs = self.bn(features)  \n",
    "        outputs = self.linear1(features)\n",
    "        #outputs = self.dropout(outputs)\n",
    "        outputs = self.linear2(outputs)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, val_dataloader, num_epochs = 10, validation = True, save_file = 'area', train_batch_size = 32, learning_rate = 5e-5):\n",
    "    history = dict()\n",
    "    train_history_loss = []\n",
    "    train_history_acc = []\n",
    "    val_history_loss = []\n",
    "    val_history_acc = []\n",
    "    model = MLP()\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    best_val_loss = np.inf\n",
    "    best_val_accuracy = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        train_loss = 0\n",
    "        batch_id = 0\n",
    "        correct = 0\n",
    "        print(f\"Epoch: {epoch + 1}\",'training')\n",
    "        for batch in train_dataloader:\n",
    "            model.train()\n",
    "            features = batch[0].to(device)\n",
    "            features = features.to(torch.float32)\n",
    "            labels = batch[1].type(torch.LongTensor).to(device)\n",
    "            outputs = model(\n",
    "                features = features\n",
    "            )\n",
    "            #print(outputs,labels)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            train_loss += loss.item()\n",
    "            _,predict_label = torch.max(outputs,1)\n",
    "            correct += (predict_label==labels).sum()\n",
    "            print('batch:', batch_id, '/',str(len(train_dataloader)), 'loss:', loss.item(), end='\\r')\n",
    "            batch_id += 1\n",
    "        average_loss = total_loss / len(train_dataloader)\n",
    "        train_history_loss.append(average_loss)\n",
    "        train_history_acc.append(correct.item()/((len(train_dataloader) - 1) * train_batch_size + len(labels)))\n",
    "        print(f\"Loss: {average_loss:.4f}\", 'accuracy:', correct.item()/((len(train_dataloader) - 1) * train_batch_size + len(labels)))\n",
    "        if validation:\n",
    "            print('validation')\n",
    "            model.eval()\n",
    "            prediction = []\n",
    "            ans = []\n",
    "            val_loss = 0.0\n",
    "            batch_id = 0\n",
    "            correct = 0\n",
    "            with torch.no_grad(): \n",
    "                for batch in val_dataloader:\n",
    "                    features = batch[0].to(device)\n",
    "                    features = features.to(torch.float32)\n",
    "                    #labels = batch['labels'].clone().detach().to(device)\n",
    "                    labels = batch[1].type(torch.LongTensor).to(device)\n",
    "                    output = model( \n",
    "                        features = features\n",
    "                    )\n",
    "                    loss = loss_function(output, labels.to(device))\n",
    "                    val_loss += loss.item()\n",
    "                    _,predict_label = torch.max(output,1)\n",
    "                    correct += (predict_label==labels).sum()  \n",
    "                    prediction.append(predict_label.cpu().item())\n",
    "                    ans.append(labels.cpu().item())\n",
    "                    print('batch:', batch_id, '/',str(len(val_dataloader)), 'loss:', loss.item(), end='\\r')\n",
    "                    batch_id += 1\n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_accuracy = correct.item() / len(val_dataloader)\n",
    "            val_history_loss.append(val_loss)\n",
    "            val_history_acc.append(val_accuracy)\n",
    "            print('loss:', val_loss)\n",
    "            print('accuracy:',val_accuracy)\n",
    "            print('f1 score:', f1_score(ans, prediction, average='macro'))\n",
    "            #if val_monitor == 'loss':\n",
    "            if val_loss <= best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                if not os.path.isdir(save_file):\n",
    "                    os.mkdir(save_file)\n",
    "                if not os.path.isdir(save_file):\n",
    "                    os.mkdir(save_file)\n",
    "                torch.save(model.state_dict(), save_file + '/model_best_loss' + '.pt')\n",
    "            if val_accuracy >= best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                if not os.path.isdir(save_file):\n",
    "                    os.mkdir(save_file)\n",
    "                if not os.path.isdir(save_file):\n",
    "                    os.mkdir(save_file)\n",
    "                #model.save_pretrained(save_file + '/model_best')\n",
    "                torch.save(model.state_dict(), save_file + '/model_best_acc' + '.pt')\n",
    "        else:\n",
    "            if not os.path.isdir(save_file):\n",
    "                    os.mkdir(save_file)\n",
    "            if not os.path.isdir(save_file):\n",
    "                os.mkdir(save_file)\n",
    "                          \n",
    "    if not os.path.isdir(save_file):\n",
    "        os.mkdir(save_file)\n",
    "    if not os.path.isdir(save_file):\n",
    "        os.mkdir(save_file)\n",
    "    torch.save(model.state_dict(), save_file + '/model_final.pt')\n",
    "    history['train_loss'] = train_history_loss\n",
    "    history['train_accuracy'] = train_history_acc\n",
    "    history['val_loss'] = val_history_loss\n",
    "    history['val_accuracy'] = val_history_acc\n",
    "    return history\n",
    "def test(test_dataloader, load_best = 'loss', load_file = 'area'):\n",
    "    print('testing')\n",
    "    if load_best == 'loss':\n",
    "        model = MLP().to(device)\n",
    "        model.load_state_dict(torch.load(load_file + \"/model_best_loss\"+ '.pt'))\n",
    "    elif load_best == 'accuracy':\n",
    "        model = MLP().to(device)\n",
    "        model.load_state_dict(torch.load(load_file + \"/model_best_loss\"+ '.pt'))\n",
    "    else:\n",
    "        #model = BertForSequenceClassification.from_pretrained(load_file + \"/model5\").to(device)\n",
    "        model = MLP().to(device)\n",
    "        model.load_state_dict(torch.load(load_file + \"/model_best_loss\"+ '.pt'))\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    ans = []\n",
    "    batch_id = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): \n",
    "        for batch in test_dataloader:\n",
    "            features = batch[0].to(device)\n",
    "            features = features.to(torch.float32)\n",
    "            #labels = torch.tensor(batch['labels'])\n",
    "            labels = batch[1].type(torch.LongTensor).to(device)\n",
    "            output = model(\n",
    "                features = features\n",
    "            )\n",
    "            _,predict_label = torch.max(output,1)\n",
    "            correct += (predict_label==labels.to(device)).sum()\n",
    "            prediction.append(predict_label.cpu().item())\n",
    "            ans.append(labels.cpu().item())\n",
    "            batch_id += 1\n",
    "            print('batch:', batch_id, end='\\r')\n",
    "    accuracy = correct.item() / len(test_dataloader)\n",
    "    f1 = f1_score(ans, prediction, average=None)\n",
    "    prec_recall = precision_recall_fscore_support(ans, prediction)\n",
    "    conf_m = confusion_matrix(prediction,ans)\n",
    "    return accuracy, f1, prec_recall,  conf_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 100\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "train_weights = class_weight.compute_class_weight(class_weight='balanced',classes = np.unique(train_labels), y=train_labels)\n",
    "weight_sp = []\n",
    "for i in train_labels:\n",
    "    if i == 0:\n",
    "        weight_sp.append(train_weights[0])\n",
    "    elif i == 1:\n",
    "        weight_sp.append(train_weights[1])\n",
    "    else:\n",
    "        weight_sp.append(train_weights[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 training\n",
      "Loss: 1.1116 accuracy: 0.34054054054054056\n",
      "validation\n",
      "loss: 1.1061208588736398422917842864996\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.19999999999999998\n",
      "Epoch: 2 training\n",
      "Loss: 1.1060 accuracy: 0.34054054054054056\n",
      "validation\n",
      "loss: 1.1001353632836115435322761535645\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.19999999999999998\n",
      "Epoch: 3 training\n",
      "Loss: 1.1004 accuracy: 0.34054054054054056\n",
      "validation\n",
      "loss: 1.0941459224337624463818550109863\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.19999999999999998\n",
      "Epoch: 4 training\n",
      "Loss: 1.0948 accuracy: 0.34054054054054056\n",
      "validation\n",
      "loss: 1.0883836547533672491135358810425\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.19999999999999998\n",
      "Epoch: 5 training\n",
      "Loss: 1.0893 accuracy: 0.34054054054054056\n",
      "validation\n",
      "loss: 1.0825498217628116517076492309577\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.19999999999999998\n",
      "Epoch: 6 training\n",
      "Loss: 1.0838 accuracy: 0.34054054054054056\n",
      "validation\n",
      "loss: 1.0766090665544783544579267501838\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.19999999999999998\n",
      "Epoch: 7 training\n",
      "Loss: 1.0781 accuracy: 0.34054054054054056\n",
      "validation\n",
      "loss: 1.0704458838417417573197841644287\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.19999999999999998\n",
      "Epoch: 8 training\n",
      "Loss: 1.0724 accuracy: 0.34594594594594597\n",
      "validation\n",
      "loss: 1.0640871155829656603219509124756\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.19999999999999998\n",
      "Epoch: 9 training\n",
      "Loss: 1.0664 accuracy: 0.35135135135135137\n",
      "validation\n",
      "loss: 1.0573696777934121634091138839722\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.19999999999999998\n",
      "Epoch: 10 training\n",
      "Loss: 1.0602 accuracy: 0.3567567567567568\n",
      "validation\n",
      "loss: 1.0506543744178045665368080139166\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.19999999999999998\n",
      "Epoch: 11 training\n",
      "Loss: 1.0539 accuracy: 0.3675675675675676\n",
      "validation\n",
      "loss: 1.0437484326816741698315143585205\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.19999999999999998\n",
      "Epoch: 12 training\n",
      "Loss: 1.0474 accuracy: 0.3891891891891892\n",
      "validation\n",
      "loss: 1.0365158546538581732691526412964\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.20689655172413793\n",
      "Epoch: 13 training\n",
      "Loss: 1.0405 accuracy: 0.41081081081081083\n",
      "validation\n",
      "loss: 1.0289550707453774767972707748413\n",
      "accuracy: 0.42857142857142855\n",
      "f1 score: 0.20689655172413793\n",
      "Epoch: 14 training\n",
      "Loss: 1.0333 accuracy: 0.43243243243243246\n",
      "validation\n",
      "loss: 1.0209806164105732805657148361206\n",
      "accuracy: 0.5238095238095238\n",
      "f1 score: 0.3703703703703704\n",
      "Epoch: 15 training\n",
      "Loss: 1.0257 accuracy: 0.4864864864864865\n",
      "validation\n",
      "loss: 1.0125977595647175847665309906006\n",
      "accuracy: 0.5238095238095238\n",
      "f1 score: 0.3703703703703704\n",
      "Epoch: 16 training\n",
      "Loss: 1.0177 accuracy: 0.572972972972973\n",
      "validation\n",
      "loss: 1.0038808839661735892430782318115\n",
      "accuracy: 0.5238095238095238\n",
      "f1 score: 0.3703703703703704\n",
      "Epoch: 17 training\n",
      "Loss: 1.0094 accuracy: 0.6054054054054054\n",
      "validation\n",
      "loss: 0.9946740837324233937985420227054\n",
      "accuracy: 0.5238095238095238\n",
      "f1 score: 0.3703703703703704\n",
      "Epoch: 18 training\n",
      "Loss: 1.0009 accuracy: 0.6108108108108108\n",
      "validation\n",
      "loss: 0.9851015153385344985102891921997\n",
      "accuracy: 0.5238095238095238\n",
      "f1 score: 0.3703703703703704\n",
      "Epoch: 19 training\n",
      "Loss: 0.9920 accuracy: 0.6162162162162163\n",
      "validation\n",
      "loss: 0.9749318957328796034312486648564\n",
      "accuracy: 0.6190476190476191\n",
      "f1 score: 0.4824242424242424\n",
      "Epoch: 20 training\n",
      "Loss: 0.9828 accuracy: 0.6162162162162163\n",
      "validation\n",
      "loss: 0.9642672254925683084457874298096\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 21 training\n",
      "Loss: 0.9732 accuracy: 0.6162162162162163\n",
      "validation\n",
      "loss: 0.9531507520448594137271165847778\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 22 training\n",
      "Loss: 0.9631 accuracy: 0.6270270270270271\n",
      "validation\n",
      "loss: 0.9415983926682245192254066467285\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 23 training\n",
      "Loss: 0.9528 accuracy: 0.6270270270270271\n",
      "validation\n",
      "loss: 0.9297303330330622249650955200195\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 24 training\n",
      "Loss: 0.9420 accuracy: 0.6324324324324324\n",
      "validation\n",
      "loss: 0.9172128694398063308006286621094\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 25 training\n",
      "Loss: 0.9304 accuracy: 0.6378378378378379\n",
      "validation\n",
      "loss: 0.9041117741948083366787195205688\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 26 training\n",
      "Loss: 0.9182 accuracy: 0.6432432432432432\n",
      "validation\n",
      "loss: 0.8907729401474908423436641693115\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 27 training\n",
      "Loss: 0.9052 accuracy: 0.6432432432432432\n",
      "validation\n",
      "loss: 0.8770639825434912475416660308838\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 28 training\n",
      "Loss: 0.8916 accuracy: 0.6486486486486487\n",
      "validation\n",
      "loss: 0.8629480273950667528505325317383\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 29 training\n",
      "Loss: 0.8774 accuracy: 0.654054054054054\n",
      "validation\n",
      "loss: 0.8482376549925122595597505569458\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 30 training\n",
      "Loss: 0.8629 accuracy: 0.6486486486486487\n",
      "validation\n",
      "loss: 0.8331207689784822661921977996826\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 31 training\n",
      "Loss: 0.8485 accuracy: 0.654054054054054\n",
      "validation\n",
      "loss: 0.81810547766231367279913425445567\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 32 training\n",
      "Loss: 0.8341 accuracy: 0.6594594594594595\n",
      "validation\n",
      "loss: 0.80315247603825167909302711486824\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 33 training\n",
      "Loss: 0.8198 accuracy: 0.6648648648648648\n",
      "validation\n",
      "loss: 0.78810808346385058512680530548125\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 34 training\n",
      "Loss: 0.8056 accuracy: 0.6648648648648648\n",
      "validation\n",
      "loss: 0.7732780412549064906972169876099\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 35 training\n",
      "Loss: 0.7915 accuracy: 0.6702702702702703\n",
      "validation\n",
      "loss: 0.75852441149098549580223560333254\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5277777777777778\n",
      "Epoch: 36 training\n",
      "Loss: 0.7775 accuracy: 0.6648648648648648\n",
      "validation\n",
      "loss: 0.74385584323179150047309398651125\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5172798216276476\n",
      "Epoch: 37 training\n",
      "Loss: 0.7637 accuracy: 0.6702702702702703\n",
      "validation\n",
      "loss: 0.72933734527656010474460124969487\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5172798216276476\n",
      "Epoch: 38 training\n",
      "Loss: 0.7502 accuracy: 0.6810810810810811\n",
      "validation\n",
      "loss: 0.71505795986879440831408500671395\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5172798216276476\n",
      "Epoch: 39 training\n",
      "Loss: 0.7369 accuracy: 0.6864864864864865\n",
      "validation\n",
      "loss: 0.70105475754964921144475936889657\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5172798216276476\n",
      "Epoch: 40 training\n",
      "Loss: 0.7238 accuracy: 0.6864864864864865\n",
      "validation\n",
      "loss: 0.6874246043818337137654066085815\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5172798216276476\n",
      "Epoch: 41 training\n",
      "Loss: 0.7109 accuracy: 0.6864864864864865\n",
      "validation\n",
      "loss: 0.67399269342422491582689285278327\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5172798216276476\n",
      "Epoch: 42 training\n",
      "Loss: 0.6982 accuracy: 0.6918918918918919\n",
      "validation\n",
      "loss: 0.6607154458761215173477649688721\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5172798216276476\n",
      "Epoch: 43 training\n",
      "Loss: 0.6856 accuracy: 0.7027027027027027\n",
      "validation\n",
      "loss: 0.64782170454661051787300109863284\n",
      "accuracy: 0.6666666666666666\n",
      "f1 score: 0.5172798216276476\n",
      "Epoch: 44 training\n",
      "Loss: 0.6731 accuracy: 0.7081081081081081\n",
      "validation\n",
      "loss: 0.63468712958551591762623786926274\n",
      "accuracy: 0.7142857142857143\n",
      "f1 score: 0.6338854382332643\n",
      "Epoch: 45 training\n",
      "Loss: 0.6610 accuracy: 0.7081081081081081\n",
      "validation\n",
      "loss: 0.62180168926715851621122360229517\n",
      "accuracy: 0.7142857142857143\n",
      "f1 score: 0.6338854382332643\n",
      "Epoch: 46 training\n",
      "Loss: 0.6493 accuracy: 0.7297297297297297\n",
      "validation\n",
      "loss: 0.60901954060509091408762931823735\n",
      "accuracy: 0.7619047619047619\n",
      "f1 score: 0.730566534914361\n",
      "Epoch: 47 training\n",
      "Loss: 0.6381 accuracy: 0.7297297297297297\n",
      "validation\n",
      "loss: 0.59673502154293511142818927764993\n",
      "accuracy: 0.7619047619047619\n",
      "f1 score: 0.730566534914361\n",
      "Epoch: 48 training\n",
      "Loss: 0.6274 accuracy: 0.7297297297297297\n",
      "validation\n",
      "loss: 0.58515328523658570818700790405277\n",
      "accuracy: 0.7619047619047619\n",
      "f1 score: 0.730566534914361\n",
      "Epoch: 49 training\n",
      "Loss: 0.6174 accuracy: 0.745945945945946\n",
      "validation\n",
      "loss: 0.57401685097387860413365364074738\n",
      "accuracy: 0.7619047619047619\n",
      "f1 score: 0.730566534914361\n",
      "Epoch: 50 training\n",
      "Loss: 0.6077 accuracy: 0.745945945945946\n",
      "validation\n",
      "loss: 0.56367350706741939907023906707765\n",
      "accuracy: 0.7619047619047619\n",
      "f1 score: 0.730566534914361\n",
      "Epoch: 51 training\n",
      "Loss: 0.5985 accuracy: 0.7567567567567568\n",
      "validation\n",
      "loss: 0.55313674520168999378259181976322\n",
      "accuracy: 0.8095238095238095\n",
      "f1 score: 0.7979797979797979\n",
      "Epoch: 52 training\n",
      "Loss: 0.5896 accuracy: 0.7621621621621621\n",
      "validation\n",
      "loss: 0.54315990582108528760504722595215\n",
      "accuracy: 0.8095238095238095\n",
      "f1 score: 0.7979797979797979\n",
      "Epoch: 53 training\n",
      "Loss: 0.5810 accuracy: 0.7621621621621621\n",
      "validation\n",
      "loss: 0.53358219475263658127050399780274\n",
      "accuracy: 0.8095238095238095\n",
      "f1 score: 0.7979797979797979\n",
      "Epoch: 54 training\n",
      "Loss: 0.5728 accuracy: 0.7675675675675676\n",
      "validation\n",
      "loss: 0.52465831683505157419650554656986\n",
      "accuracy: 0.8095238095238095\n",
      "f1 score: 0.7979797979797979\n",
      "Epoch: 55 training\n",
      "Loss: 0.5649 accuracy: 0.7783783783783784\n",
      "validation\n",
      "loss: 0.51568506445203516671671867370677\n",
      "accuracy: 0.8095238095238095\n",
      "f1 score: 0.7979797979797979\n",
      "Epoch: 56 training\n",
      "Loss: 0.5574 accuracy: 0.7783783783783784\n",
      "validation\n",
      "loss: 0.50717716185109955890731811523447\n",
      "accuracy: 0.8095238095238095\n",
      "f1 score: 0.7979797979797979\n",
      "Epoch: 57 training\n",
      "Loss: 0.5502 accuracy: 0.7837837837837838\n",
      "validation\n",
      "loss: 0.49962919932745753071382522583373\n",
      "accuracy: 0.8095238095238095\n",
      "f1 score: 0.7979797979797979\n",
      "Epoch: 58 training\n",
      "Loss: 0.5433 accuracy: 0.7837837837837838\n",
      "validation\n",
      "loss: 0.49201867764904383196386337280274\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 59 training\n",
      "Loss: 0.5367 accuracy: 0.7891891891891892\n",
      "validation\n",
      "loss: 0.48462263982565633306822776794433\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 60 training\n",
      "Loss: 0.5303 accuracy: 0.7891891891891892\n",
      "validation\n",
      "loss: 0.47743439417155015338008880615236\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 61 training\n",
      "Loss: 0.5241 accuracy: 0.7945945945945946\n",
      "validation\n",
      "loss: 0.47044831017653151331000328063966\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 62 training\n",
      "Loss: 0.5180 accuracy: 0.7945945945945946\n",
      "validation\n",
      "loss: 0.46415837978323320312476158142154\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 63 training\n",
      "Loss: 0.5121 accuracy: 0.7945945945945946\n",
      "validation\n",
      "loss: 0.457574140723972072396283149719266\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 64 training\n",
      "Loss: 0.5063 accuracy: 0.882054042816164\n",
      "validation\n",
      "loss: 0.45121581231554358130600452423146\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 65 training\n",
      "Loss: 0.5006 accuracy: 0.8054054054054054\n",
      "validation\n",
      "loss: 0.44503174119052435991698741912846\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 66 training\n",
      "Loss: 0.4950 accuracy: 0.8108108108108109\n",
      "validation\n",
      "loss: 0.43941613765699525808832645416264\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 67 training\n",
      "Loss: 0.4896 accuracy: 0.8108108108108109\n",
      "validation\n",
      "loss: 0.43345230063867.14613068103790285\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 68 training\n",
      "Loss: 0.4842 accuracy: 0.8108108108108109\n",
      "validation\n",
      "loss: 0.42761303431221415390719890594486\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 69 training\n",
      "Loss: 0.4789 accuracy: 0.8216216216216217\n",
      "validation\n",
      "loss: 0.42182902858725622084233760833744\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 70 training\n",
      "Loss: 0.4736 accuracy: 0.8216216216216217\n",
      "validation\n",
      "loss: 0.41660919874196960806393623352057\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 71 training\n",
      "Loss: 0.4685 accuracy: 0.8216216216216217\n",
      "validation\n",
      "loss: 0.41104036285763695588301181793215\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 72 training\n",
      "Loss: 0.4633 accuracy: 0.8324324324324325\n",
      "validation\n",
      "loss: 0.405684429886085663357334136963183\n",
      "accuracy: 0.8571428571428571\n",
      "f1 score: 0.8412698412698413\n",
      "Epoch: 73 training\n",
      "Loss: 0.4583 accuracy: 0.8432432432432433\n",
      "validation\n",
      "loss: 0.40049157814965364086610794067387\n",
      "accuracy: 0.9047619047619048\n",
      "f1 score: 0.9\n",
      "Epoch: 74 training\n",
      "Loss: 0.4533 accuracy: 0.8432432432432433\n",
      "validation\n",
      "loss: 0.39516596983940827824625492095956\n",
      "accuracy: 0.9047619047619048\n",
      "f1 score: 0.9\n",
      "Epoch: 75 training\n",
      "Loss: 0.4483 accuracy: 0.8432432432432433\n",
      "validation\n",
      "loss: 0.39040518866940624512441158294686\n",
      "accuracy: 0.9047619047619048\n",
      "f1 score: 0.9\n",
      "Epoch: 76 training\n",
      "Loss: 0.4433 accuracy: 0.8432432432432433\n",
      "validation\n",
      "loss: 0.385197546111331131967401504516645\n",
      "accuracy: 0.9047619047619048\n",
      "f1 score: 0.9\n",
      "Epoch: 77 training\n",
      "Loss: 0.4384 accuracy: 0.8432432432432433\n",
      "validation\n",
      "loss: 0.38015271226565045881718635559087\n",
      "accuracy: 0.9523809523809523\n",
      "f1 score: 0.952153110047847\n",
      "Epoch: 78 training\n",
      "Loss: 0.4335 accuracy: 0.8486486486486486\n",
      "validation\n",
      "loss: 0.37526873286281315535655021667488\n",
      "accuracy: 0.9523809523809523\n",
      "f1 score: 0.952153110047847\n",
      "Epoch: 79 training\n",
      "Loss: 0.4286 accuracy: 0.8648648648648649\n",
      "validation\n",
      "loss: 0.370450252090536491908073425293984\n",
      "accuracy: 0.9523809523809523\n",
      "f1 score: 0.952153110047847\n",
      "Epoch: 80 training\n",
      "Loss: 0.4237 accuracy: 0.8756756756756757\n",
      "validation\n",
      "loss: 0.365524081114147478542447090148925\n",
      "accuracy: 0.9523809523809523\n",
      "f1 score: 0.952153110047847\n",
      "Epoch: 81 training\n",
      "Loss: 0.4188 accuracy: 0.8756756756756757\n",
      "validation\n",
      "loss: 0.361108972646650865352416038513294\n",
      "accuracy: 0.9523809523809523\n",
      "f1 score: 0.952153110047847\n",
      "Epoch: 82 training\n",
      "Loss: 0.4139 accuracy: 0.8756756756756757\n",
      "validation\n",
      "loss: 0.356388857987310251698422431945803\n",
      "accuracy: 0.9523809523809523\n",
      "f1 score: 0.952153110047847\n",
      "Epoch: 83 training\n",
      "Loss: 0.4090 accuracy: 0.8810810810810811\n",
      "validation\n",
      "loss: 0.351608297876304138181281089782727\n",
      "accuracy: 0.9523809523809523\n",
      "f1 score: 0.952153110047847\n",
      "Epoch: 84 training\n",
      "Loss: 0.4041 accuracy: 0.8810810810810811\n",
      "validation\n",
      "loss: 0.346911309774787724221813678741583\n",
      "accuracy: 0.9523809523809523\n",
      "f1 score: 0.952153110047847\n",
      "Epoch: 85 training\n",
      "Loss: 0.3992 accuracy: 0.8810810810810811\n",
      "validation\n",
      "loss: 0.34262021138731924058927774429323\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 86 training\n",
      "Loss: 0.3944 accuracy: 0.8810810810810811\n",
      "validation\n",
      "loss: 0.338002527487419996620213985443136\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 87 training\n",
      "Loss: 0.3895 accuracy: 0.8810810810810811\n",
      "validation\n",
      "loss: 0.333436618292970333247435092926304\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 88 training\n",
      "Loss: 0.3845 accuracy: 0.8864864864864865\n",
      "validation\n",
      "loss: 0.328678833187690869376778602600168\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 89 training\n",
      "Loss: 0.3794 accuracy: 0.8864864864864865\n",
      "validation\n",
      "loss: 0.32404900085003685594934225082402\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 90 training\n",
      "Loss: 0.3743 accuracy: 0.8864864864864865\n",
      "validation\n",
      "loss: 0.319656456598923332315196990966874\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 91 training\n",
      "Loss: 0.3693 accuracy: 0.8864864864864865\n",
      "validation\n",
      "loss: 0.315093920255700778519701957702675\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 92 training\n",
      "Loss: 0.3643 accuracy: 0.8972972972972973\n",
      "validation\n",
      "loss: 0.310859797123287434897894859314425\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 93 training\n",
      "Loss: 0.3593 accuracy: 0.8972972972972973\n",
      "validation\n",
      "loss: 0.30642511912931997110448598861699\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 94 training\n",
      "Loss: 0.3543 accuracy: 0.8972972972972973\n",
      "validation\n",
      "loss: 0.30218558155355.788147926330566464\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 95 training\n",
      "Loss: 0.3493 accuracy: 0.8972972972972973\n",
      "validation\n",
      "loss: 0.29767876779217095506643533706676\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 96 training\n",
      "Loss: 0.3444 accuracy: 0.8972972972972973\n",
      "validation\n",
      "loss: 0.293439667893662361739253997802725\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 97 training\n",
      "Loss: 0.3394 accuracy: 0.8972972972972973\n",
      "validation\n",
      "loss: 0.289120293754552148698890209198244\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 98 training\n",
      "Loss: 0.3345 accuracy: 0.9027027027027027\n",
      "validation\n",
      "loss: 0.284916407827820135050261020660465\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 99 training\n",
      "Loss: 0.3296 accuracy: 0.9081081081081082\n",
      "validation\n",
      "loss: 0.280586992479151221819043159484938\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n",
      "Epoch: 100 training\n",
      "Loss: 0.3247 accuracy: 0.9081081081081082\n",
      "validation\n",
      "loss: 0.27661141438320990869642496109012\n",
      "accuracy: 1.0\n",
      "f1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(train_features)\n",
    "train_feature = scaler.transform(train_features)\n",
    "#train_feature, val_feature, train_label, val_label = train_test_split(train_features, train_labels, test_size=0.1, random_state=42)\n",
    "#train_feature, val_feature, train_label, val_label = train_test_split(train_feature, train_labels, test_size=0.1, random_state=42)\n",
    "train_feature, val_feature, train_label, val_label, train_sp, val_sp = train_test_split(train_feature, train_labels, weight_sp, test_size=0.1, random_state=42)\n",
    "train_dataset = TrainDataset(features=train_feature, label = train_label)\n",
    "sampler = WeightedRandomSampler(train_sp, len(train_sp))\n",
    "train_dataloader =  DataLoader(train_dataset,batch_size=batch_size,shuffle=False, sampler = sampler)\n",
    "train_dataloader =  DataLoader(train_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "val_dataset = TrainDataset(features=val_feature, label = val_label)\n",
    "val_dataloader =  DataLoader(val_dataset,batch_size=1,shuffle=False)\n",
    "#test_choi = StandardScaler().fit_transform(features[test])\n",
    "\n",
    "\n",
    "history = train(train_dataloader, val_dataloader,num_epochs=epochs, train_batch_size = batch_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n",
      "test accuracy: 0.9423076923076923 f1 score: [0.95454545 0.90322581 0.96551724]\n",
      "[[21  2  0]\n",
      " [ 0 14  0]\n",
      " [ 0  1 14]]\n"
     ]
    }
   ],
   "source": [
    "test_feature = scaler.transform(test_features)\n",
    "test_dataset = TrainDataset(features=test_feature, label = test_labels)\n",
    "test_dataloader =  DataLoader(test_dataset,batch_size=1,shuffle=False)\n",
    "\n",
    "accuracy, f1, prec_recall, confusion_m = test(test_dataloader, load_best='acc')\n",
    "print(\"test accuracy:\",accuracy,\"f1 score:\",f1)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n",
      "test accuracy: 0.9423076923076923 f1 score: [0.95454545 0.90322581 0.96551724]\n",
      "[[21  2  0]\n",
      " [ 0 14  0]\n",
      " [ 0  1 14]]\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, prec_recall, confusion_m = test(test_dataloader, load_best='final')\n",
    "print(\"test accuracy:\",accuracy,\"f1 score:\",f1)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.52087379e+01  1.17634529e+01 -6.38786408e+01  8.40177676e+00\n",
      " -6.43106796e+01  8.96885582e+00 -6.75485437e+01  1.38230567e+01\n",
      "  9.22330097e-01  6.31067961e-02  9.66019417e-01  3.39805825e-02\n",
      "  9.41747573e-01  5.82524272e-02  9.75728155e-01  1.94174757e-02]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.96894382e+01 5.07900083e+01 3.28153690e+01 1.71800580e+01\n",
      " 3.74374588e+01 2.09475039e+01 5.73156047e+01 4.69009149e+01\n",
      " 7.16372891e-02 5.91243284e-02 3.28259025e-02 3.28259025e-02\n",
      " 5.48590819e-02 5.48590819e-02 2.36827222e-02 1.90404374e-02]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'loss history')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('loss history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'accuracy history')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('accuracy history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "1/5: Converting Node Type Gemm\n",
      "2/5: Converting Node Type Relu\n",
      "3/5: Converting Node Type Gemm\n",
      "4/5: Converting Node Type Relu\n",
      "5/5: Converting Node Type Gemm\n",
      "Translation to CoreML spec completed. Now compiling the CoreML model.\n",
      "Model Compilation done.\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.load_state_dict(torch.load('area/model_best_loss.pt'))\n",
    "dummy_input = torch.randn(1,16)\n",
    "torch.onnx.export(model.cpu(), dummy_input, \"model_a.onnx\", input_names=[\"input\"], output_names=[\"output\"])\n",
    "onnx_path = 'model_a.onnx'\n",
    "ml_model = ct.converters.onnx.convert(model=onnx_path)\n",
    "ml_model.save(\"model_area.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.0.weight Parameter containing:\n",
      "tensor([[-0.0184,  0.4811, -0.2804,  0.2753,  0.0270, -0.1509,  0.3156, -0.4992,\n",
      "         -0.1103, -0.4165,  0.1791, -0.2403,  0.2271, -0.3347, -0.0216, -0.0939],\n",
      "        [-0.0238, -0.1248, -0.0558, -0.2458, -0.0453, -0.0135,  0.0234,  0.0968,\n",
      "          0.0500, -0.0658,  0.1558, -0.0426, -0.0486, -0.0632, -0.1930,  0.2597],\n",
      "        [ 0.2405,  0.0599,  0.1062, -0.0947, -0.0244, -0.0127,  0.0119, -0.1327,\n",
      "         -0.2456, -0.1880, -0.1669, -0.1629, -0.0763, -0.2277, -0.1276,  0.1569],\n",
      "        [-0.1372,  0.1740, -0.0049,  0.2824,  0.0446,  0.1892,  0.2385, -0.4542,\n",
      "          0.2906, -0.0885,  0.1699, -0.3644,  0.3138, -0.0619, -0.0868,  0.0525],\n",
      "        [-0.1020,  0.1135,  0.0221, -0.2189,  0.0224, -0.1825, -0.2134,  0.2009,\n",
      "          0.1802, -0.2133,  0.1003,  0.0942, -0.0641,  0.1453, -0.0466,  0.0463],\n",
      "        [ 0.1398, -0.5111, -0.1318,  0.1304, -0.1797,  0.3363, -0.1012,  0.1127,\n",
      "          0.1829, -0.0414,  0.2419,  0.0955, -0.1623,  0.2464, -0.1880, -0.0629],\n",
      "        [ 0.0921,  0.2301, -0.2329,  0.0043,  0.0365, -0.0680,  0.3334, -0.3168,\n",
      "          0.1931, -0.0681, -0.0364, -0.0291, -0.1586, -0.1382, -0.0012,  0.0023],\n",
      "        [ 0.0147, -0.3247, -0.0142,  0.0751, -0.1224,  0.3098,  0.1481,  0.1240,\n",
      "         -0.3048,  0.0293,  0.0994,  0.0772, -0.0113, -0.3013, -0.1159, -0.1427],\n",
      "        [ 0.1764, -0.5426, -0.2611, -0.0126, -0.1512,  0.1546, -0.0193,  0.2785,\n",
      "          0.0431, -0.1473,  0.1145, -0.0227, -0.0746, -0.1576, -0.1238, -0.3357],\n",
      "        [ 0.0625, -0.4294, -0.1091, -0.0226, -0.2384,  0.2369, -0.3896,  0.0969,\n",
      "          0.1863, -0.0634,  0.2163,  0.0517,  0.1301, -0.1800,  0.0598,  0.1164],\n",
      "        [ 0.2006, -0.3682, -0.3005,  0.2141, -0.2687,  0.4081, -0.0110,  0.0306,\n",
      "          0.1257,  0.3684, -0.0727, -0.4100,  0.0385, -0.2158, -0.1121, -0.2814],\n",
      "        [-0.2579,  0.2958,  0.0340, -0.4079,  0.1597, -0.1597, -0.0329, -0.0142,\n",
      "          0.2831, -0.5435,  0.0212,  0.0557,  0.2715, -0.3936,  0.0891, -0.3707],\n",
      "        [ 0.2695, -0.1320,  0.0563, -0.0155,  0.0829,  0.1554, -0.2092,  0.1522,\n",
      "         -0.1992,  0.1647, -0.0577, -0.0015,  0.0245,  0.1652, -0.0449,  0.2609],\n",
      "        [ 0.1263, -0.2162, -0.0803, -0.3330, -0.0386,  0.0147,  0.0214,  0.5065,\n",
      "          0.3868,  0.1031, -0.2849,  0.1031, -0.0337, -0.2543,  0.1954,  0.1144],\n",
      "        [ 0.2597, -0.3287, -0.2071,  0.2664,  0.0931, -0.0950, -0.3081,  0.3656,\n",
      "         -0.2564,  0.2186, -0.0418,  0.1352,  0.2853, -0.0590,  0.1328, -0.1484],\n",
      "        [-0.2671,  0.1846,  0.1711, -0.0031, -0.0167, -0.0045,  0.1453, -0.4489,\n",
      "          0.2884, -0.2369,  0.4048, -0.1673,  0.0790,  0.0147,  0.4237, -0.3622]],\n",
      "       requires_grad=True)\n",
      "linear1.0.bias Parameter containing:\n",
      "tensor([ 0.0098,  0.1817, -0.1194,  0.1121,  0.2216,  0.1282, -0.0416, -0.0653,\n",
      "         0.2947,  0.1957,  0.0890,  0.0880,  0.1549,  0.5509,  0.3113,  0.2042],\n",
      "       requires_grad=True)\n",
      "linear1.2.weight Parameter containing:\n",
      "tensor([[ 0.1431,  0.1797, -0.1564, -0.0633,  0.0034,  0.1865, -0.1168,  0.2615,\n",
      "          0.2186,  0.1788,  0.0595, -0.2744,  0.0516,  0.1133,  0.2636, -0.1684],\n",
      "        [-0.2576,  0.0483, -0.1502,  0.0375,  0.0431,  0.1827, -0.0336,  0.2914,\n",
      "          0.5393,  0.4244,  0.2914,  0.1865, -0.0687,  0.6080,  0.3015, -0.0647],\n",
      "        [ 0.3657, -0.1123, -0.0953,  0.2362,  0.0060, -0.1999, -0.0965, -0.2647,\n",
      "         -0.2339,  0.1020,  0.2163,  0.2550,  0.0130, -0.0315,  0.0012,  0.1719],\n",
      "        [-0.0496, -0.2102, -0.1969,  0.0809, -0.3189,  0.4107,  0.0019,  0.2837,\n",
      "          0.2490,  0.3846,  0.3251, -0.3522,  0.1531,  0.1976,  0.2006, -0.1893],\n",
      "        [ 0.2006, -0.3573, -0.1743,  0.2908, -0.0022, -0.1859,  0.2327, -0.1422,\n",
      "         -0.2395, -0.3129, -0.1210,  0.0720, -0.1128, -0.1815, -0.0170,  0.4272],\n",
      "        [ 0.3116, -0.3067, -0.0583,  0.4129, -0.3021, -0.0640, -0.0281, -0.1205,\n",
      "          0.0986, -0.1355, -0.0131,  0.0096,  0.2135, -0.0554, -0.1404,  0.1944],\n",
      "        [ 0.3439,  0.0691,  0.2827,  0.4712, -0.1745,  0.0785,  0.3000, -0.0097,\n",
      "          0.0510,  0.1509, -0.0791, -0.0938,  0.2230, -0.1933, -0.0557, -0.0625],\n",
      "        [-0.3156, -0.1142, -0.0110, -0.2154,  0.0398,  0.1199, -0.1255,  0.4590,\n",
      "          0.0081, -0.0764,  0.4020, -0.0850, -0.0697, -0.1008,  0.2590, -0.3914]],\n",
      "       requires_grad=True)\n",
      "linear1.2.bias Parameter containing:\n",
      "tensor([-0.3237,  0.3455,  0.3049, -0.0384,  0.1622, -0.0621,  0.0896,  0.1870],\n",
      "       requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[ 0.0639, -0.6427,  0.3207, -0.2913,  0.2432, -0.0146,  0.3895, -0.3820],\n",
      "        [-0.1911,  0.0342, -0.1138, -0.3470, -0.2607, -0.5254, -0.3819, -0.4393],\n",
      "        [ 0.2528, -0.0086, -0.6959,  0.4172, -0.4309, -0.2625,  0.1677,  0.1719]],\n",
      "       requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([0.1822, 0.4318, 0.0547], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "\n",
    "model.load_state_dict(torch.load('area/model_best_loss.pt'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 输入张量示例\n",
    "example_input = torch.rand(1, 16)\n",
    "\n",
    "# 将模型转换为 TorchScript 格式\n",
    "traced_model = torch.jit.trace(model, example_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
